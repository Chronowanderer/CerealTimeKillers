{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "# Executing `set_seed(seed=seed)` you are setting the seed to ensure reproducibility.\n",
    "\n",
    "# for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed = None, seed_torch = True):\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental settings\n",
    "N_subject = 4\n",
    "N_game = 4\n",
    "\n",
    "Subject_names = ['01', '02', '03', '04']\n",
    "Game_names = ['1', '2', '3', '4']\n",
    "\n",
    "if len(Subject_names) != N_subject:\n",
    "    print('Subject list error!')\n",
    "if len(Game_names) != N_game:\n",
    "    print('Game list error!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels used for prediction: Label_info + Label_electrode --> Label_prediction\n",
    "# CHANGE these with necessity\n",
    "\n",
    "# ['subject', 'game', 'gender', 'age', 'disturbance', 'experience', 'memory']\n",
    "Label_info = []\n",
    "\n",
    "# ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "Label_electrode = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "\n",
    "# ['satisfied', 'boring', 'horrible', 'calm', 'funny', 'valence', 'arounsal']\n",
    "Label_prediction = ['boring', 'horrible', 'calm', 'funny']\n",
    "# Label_prediction = ['valence', 'arounsal']\n",
    "\n",
    "# Summarise labels for model\n",
    "Label_names = Label_info + Label_electrode + Label_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (2, 14)  Output shape: (1, 4)\n",
      "Random seed 2021 has been set.\n"
     ]
    }
   ],
   "source": [
    "# Model structural settings\n",
    "N_inputtime = 2 # Time window for input sampling\n",
    "N_leaptime = 2 # Temporal leap for input sampling\n",
    "N_outputtime = 1 # Time window for output (FIX to 1 for emotional state prediction!)\n",
    "\n",
    "N_channel = len(Label_info + Label_electrode)\n",
    "N_emotion = len(Label_prediction)\n",
    "N_input = (N_inputtime, N_channel)\n",
    "N_output = (N_outputtime, N_emotion)\n",
    "print('Input shape:', N_input, ' Output shape:', N_output)\n",
    "\n",
    "# Model training settings\n",
    "test_ratio = 0.2 # proportion of testing data to full dataset\n",
    "batch_size_train = 64 # number of examples per minibatch during training\n",
    "batch_size_test = 256 # number of examples per minibatch during validation & testing\n",
    "k_folds = 5 # number for K-folds\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 2021\n",
    "set_seed(seed = SEED) # With this code, do we still need to set random seed afterwards?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read summarised data from csv\n",
    "def read_smry_data(subject, game, label):\n",
    "    data = pd.read_csv('Summarised_Data/' + 'S' + subject + 'G' + game + '.csv', index_col = ['time'])\n",
    "    return pd.DataFrame(data, columns = label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time series to supervised learning\n",
    "def series_to_supervised(data, n_leap = 1, n_in = 1, n_out = 1, col_fix = [], col_in = [], col_out = [], dropnan = True):\n",
    "    cols, names_input, names_output = list(), list(), list()\n",
    "    \n",
    "    # Input non-sequence from col_fix\n",
    "    if len(col_fix):\n",
    "        df = pd.DataFrame(data, columns = col_fix)\n",
    "        cols.append(df)\n",
    "        names_input += [('%s' % (df.columns[j])) for j in range(df.shape[1])]\n",
    "    \n",
    "    # Input sequence (t - n - 1, ..., t - 1, t) from col_in\n",
    "    if len(col_in):\n",
    "        df = pd.DataFrame(data, columns = col_in)\n",
    "        for i in range(n_in - 1, -1, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            if i == 0:\n",
    "                names_input += [('%s(t)' % (df.columns[j])) for j in range(df.shape[1])]\n",
    "            else:\n",
    "                names_input += [('%s(t-%d)' % (df.columns[j], i)) for j in range(df.shape[1])]\n",
    "    \n",
    "    # Forecast sequence (t, t + 1, ..., t + n) from col_out\n",
    "    if len(col_out):\n",
    "        df = pd.DataFrame(data, columns = col_out)\n",
    "        for i in range(0, n_out):\n",
    "            cols.append(df.shift(-i))\n",
    "            if i == 0:\n",
    "                names_output += [('%s(t)' % (df.columns[j])) for j in range(df.shape[1])]\n",
    "            else:\n",
    "                names_output += [('%s(t+%d)' % (df.columns[j], i)) for j in range(df.shape[1])]\n",
    "    \n",
    "    # Merge dataframe\n",
    "    data = pd.concat(cols, axis = 1)\n",
    "    data.columns = names_input + names_output\n",
    "    if dropnan:\n",
    "        data.dropna(inplace = True)\n",
    "    \n",
    "    # Temporal leap sampling\n",
    "    data = data.iloc[::n_leap]\n",
    "    \n",
    "    # Return dataframe and input/output labels\n",
    "    return data.reset_index(drop = True), names_input, names_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent labels: ['AF3(t-1)', 'AF4(t-1)', 'F3(t-1)', 'F4(t-1)', 'F7(t-1)', 'F8(t-1)', 'FC5(t-1)', 'FC6(t-1)', 'O1(t-1)', 'O2(t-1)', 'P7(t-1)', 'P8(t-1)', 'T7(t-1)', 'T8(t-1)', 'AF3(t)', 'AF4(t)', 'F3(t)', 'F4(t)', 'F7(t)', 'F8(t)', 'FC5(t)', 'FC6(t)', 'O1(t)', 'O2(t)', 'P7(t)', 'P8(t)', 'T7(t)', 'T8(t)']\n",
      "Dependent labels: ['boring(t)', 'horrible(t)', 'calm(t)', 'funny(t)']\n",
      "Subject dataset size: (76504, 32)\n"
     ]
    }
   ],
   "source": [
    "# Convert time series to data for supervised learning\n",
    "TS_data = [ [] for j in range(N_subject) ]\n",
    "\n",
    "# Within-subject processing\n",
    "# Need to change in the future for between-subject processing\n",
    "for i_subject in range(N_subject):\n",
    "    subject = Subject_names[i_subject]\n",
    "    \n",
    "    for i_game in range(N_game):\n",
    "        game = Game_names[i_game]\n",
    "        \n",
    "        # Read summarised data\n",
    "        Read_data = read_smry_data(subject, game, Label_names)\n",
    "        \n",
    "        # Convert time series to supervised learning\n",
    "        Temp_data, X_label, Y_label = series_to_supervised(Read_data, n_leap = N_leaptime, n_in = N_inputtime, n_out = N_outputtime, \n",
    "                                                           col_fix = Label_info, col_in = Label_electrode, col_out = Label_prediction)\n",
    "        \n",
    "        # Add splitted datasets\n",
    "        if i_game:\n",
    "            TS_data[i_subject] = pd.concat([TS_data[i_subject], Temp_data], ignore_index = True)\n",
    "        else:\n",
    "            TS_data[i_subject] = Temp_data\n",
    "\n",
    "# Show independent/dependent variables for model prediction\n",
    "print('Independent labels:', X_label)\n",
    "print('Dependent labels:', Y_label)\n",
    "print('Subject dataset size:', TS_data[i_subject].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "# YET to be used at this point!!! (waiting for Q&A)\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 Subject\n",
      "----------------------------\n",
      "1/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "2/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "3/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "4/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "5/5 Fold\n",
      "Train/Val/Test Dataset Length: 48964 12240 15300\n",
      "\n",
      "\n",
      "2/4 Subject\n",
      "----------------------------\n",
      "1/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "2/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "3/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "4/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "5/5 Fold\n",
      "Train/Val/Test Dataset Length: 48964 12240 15300\n",
      "\n",
      "\n",
      "3/4 Subject\n",
      "----------------------------\n",
      "1/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "2/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "3/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "4/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "5/5 Fold\n",
      "Train/Val/Test Dataset Length: 48964 12240 15300\n",
      "\n",
      "\n",
      "4/4 Subject\n",
      "----------------------------\n",
      "1/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "2/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "3/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "4/5 Fold\n",
      "Train/Val/Test Dataset Length: 48963 12241 15300\n",
      "\n",
      "\n",
      "5/5 Fold\n",
      "Train/Val/Test Dataset Length: 48964 12240 15300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# Create the corresponding DataLoaders for training and testing\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "# Within-subject training & testing\n",
    "for i_subject in range(N_subject):\n",
    "    # Print current subject\n",
    "    print('%d/%d Subject' % (i_subject + 1, N_subject))\n",
    "    print('----------------------------')\n",
    "    \n",
    "    # Load full dataset from subject\n",
    "    full_dataset = TS_data[i_subject]\n",
    "    \n",
    "    # Split into train/test datasets\n",
    "    test_size = int(test_ratio * len(full_dataset))\n",
    "    train_size = len(full_dataset) - test_size\n",
    "    train_set_orig, test_set_orig = torch.utils.data.random_split(full_dataset, [train_size, test_size], generator = g_seed)\n",
    "    \n",
    "    # Test dataset loader\n",
    "    test_loader = torch.utils.data.DataLoader(test_set_orig,\n",
    "                                              batch_size = batch_size_test,\n",
    "                                              num_workers = 2,\n",
    "                                              worker_init_fn = seed_worker,\n",
    "                                              generator = g_seed)\n",
    "    \n",
    "    # K-fold Cross Validator\n",
    "    kfold = KFold(n_splits = k_folds, shuffle = True, random_state = SEED)\n",
    "    for fold, (train_i, val_i) in enumerate(kfold.split(train_set_orig)):\n",
    "        # Print current fold\n",
    "        print('%d/%d Fold' % (fold + 1, k_folds))\n",
    "        \n",
    "        # Sample train/validation dataset from indices\n",
    "        train_sampler = torch.utils.data.SubsetRandomSampler(train_i, generator = g_seed)\n",
    "        val_sampler = torch.utils.data.SubsetRandomSampler(val_i, generator = g_seed)\n",
    "        \n",
    "        # Train/Validation dataset loader\n",
    "        train_loader = torch.utils.data.DataLoader(train_set_orig,\n",
    "                                                   sampler = train_sampler,\n",
    "                                                   batch_size = batch_size_train,\n",
    "                                                   num_workers = 2,\n",
    "                                                   worker_init_fn = seed_worker,\n",
    "                                                   generator = g_seed)\n",
    "        val_loader = torch.utils.data.DataLoader(train_set_orig,\n",
    "                                                 sampler = val_sampler,\n",
    "                                                 batch_size = batch_size_test,\n",
    "                                                 num_workers = 2,\n",
    "                                                 worker_init_fn = seed_worker,\n",
    "                                                 generator = g_seed)\n",
    "        \n",
    "        # Model training & evalucation\n",
    "        ...\n",
    "        \n",
    "        # Fold output\n",
    "        ...\n",
    "        print('Train/Val/Test Dataset Length:', len(train_sampler), len(val_sampler), test_size)\n",
    "        print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
