{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import spectrogram\n",
    "\n",
    "# ML packages\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, random_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Setup package manually implemented\n",
    "from setup import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CerealTimeKillersDataset(Dataset):\n",
    "    \"\"\"Spectrogram dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.ori_dataframe = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ori_dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        spectrogram = self.ori_dataframe.iloc[idx, -1]\n",
    "        labels = self.ori_dataframe.iloc[idx, :-1]\n",
    "        labels = dict(labels)\n",
    "        sample = {'spectrogram': spectrogram, 'labels': labels}\n",
    "\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specgram(file_dir, labels, winlen = 0, stride = 1, nperseg = 256, fs = 129):\n",
    "    \n",
    "    # Reading from the csv data set (can do matlab as well) using pandas. \n",
    "    df = pd.read_csv(file_dir, sep = ',')\n",
    "    df = pd.DataFrame(df, columns = labels)\n",
    "    d = np.array(df, dtype = float) # Switching from pandas to numpy array as this might be more comfortable for people\n",
    "    \n",
    "    full_spec = []\n",
    "    for idx, d2 in enumerate(d.T):\n",
    "        _, _, Sxx = spectrogram(d2, nperseg = nperseg, fs = fs)\n",
    "        full_spec.append(Sxx)\n",
    "        \n",
    "    #DIMENSIONS OF FULL_SPEC WITHOUT WINDOWING (I.E. FULL WINDOWING)\n",
    "    #DIMENSION 1: 1                      - FOR DIMENSIONAL CONSISTENCY\n",
    "    #DIMENSION 2: TIME      (DEFAULT=170) - MIGHT CHANGE AS WELL OK - WE ARE WORKING ON IT\n",
    "    #DIMENSION 3: CHANNELS  (DEFAULT=14) - MIGHT CHANGE (SO NOT REALLY DEFAULT BUT OK)\n",
    "    #DIMENSION 4: FREQUENCY (DEFAULT=129)\n",
    "    \n",
    "    full_spec = np.vstack([full_spec])\n",
    "    full_spec = np.moveaxis(full_spec, -1, 0)\n",
    "    if winlen == 0:\n",
    "        return np.array([full_spec])\n",
    "    \n",
    "    i = 0\n",
    "    full_spec_wind = []\n",
    "    while i * stride + winlen < full_spec.shape[-1]:\n",
    "        full_spec_wind.append(full_spec[i * stride : i * stride + winlen, : , :])\n",
    "        i += 1\n",
    "    \n",
    "    #DIMENSIONS OF FULL_SPEC WITH WINDOWING    (FULL_SPEC_WIND) \n",
    "    #DIMENSION 1: TIME      (NO DEFAULT - SORRY)\n",
    "    #DIMENSION 2: WINDOWS   (DEFAULT=1)\n",
    "    #DIMENSION 3: CHANNELS  (DEFAULT=14) - MIGHT CHANGE (SO NOT REALLY DEFAULT BUT OK)\n",
    "    #DIMENSION 4: FREQUENCY (DEFAULT=129)\n",
    "    \n",
    "    full_spec_wind = np.array(full_spec_wind)\n",
    "    return full_spec_wind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CerealTimeKillersDataLoader(dir_class, label_class, is_between_subject = False, \n",
    "                                winlen = 0, stride = 1, nperseg = 256, fs = 129):\n",
    "    \n",
    "    specgram_name = 'full_specgram_1'\n",
    "    \n",
    "    # Load label & EEG data\n",
    "    labels_df = pd.read_csv(dir_class.label)\n",
    "    if is_between_subject:\n",
    "        spec_df = pd.DataFrame(columns = label_class.fixed + [specgram_name], dtype = float)\n",
    "    else:\n",
    "        spec_df = pd.DataFrame(labels_df, columns = label_class.fixed + [specgram_name], dtype = float)\n",
    "        spec_df[specgram_name] = [[]] * len(spec_df)\n",
    "    \n",
    "    for idx in range(labels_df.shape[0]): \n",
    "        subject = labels_df['subject'].iloc[idx]\n",
    "        game = labels_df['game'].iloc[idx]\n",
    "    \n",
    "        # You can also just paste in the Directory of the csv file - on windows you may have to change the slash direction\n",
    "        DirComb = f'{dir_class.game}/(S{str(subject).zfill(2)})/Preprocessed EEG Data/.csv format/S{str(subject).zfill(2)}G{str(game)}AllChannels.csv'\n",
    "        \n",
    "        # Get EEG spectrum\n",
    "        spec_EEG = get_specgram(DirComb, label_class.electrode, \n",
    "                                winlen = winlen, stride = stride, nperseg = nperseg, fs = fs)\n",
    "        if is_between_subject:\n",
    "            new_list = list()\n",
    "            for i in range(spec_EEG.shape[0]):\n",
    "                new_list.append(list(labels_df[label_class.fixed].iloc[idx]) + [spec_EEG[i]])\n",
    "            new_df = pd.DataFrame(new_list, columns = label_class.fixed + [specgram_name], dtype = float)\n",
    "            spec_df = pd.concat([spec_df, new_df], ignore_index = True)\n",
    "        else:\n",
    "            spec_df[specgram_name].iloc[idx] = spec_EEG\n",
    "\n",
    "    # Save dataset\n",
    "    return CerealTimeKillersDataset(spec_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CerealTimeKillersDataSplitter(full_dataset,\n",
    "                                  batch_size_train = 64, batch_size_test = 256, \n",
    "                                  test_ratio = 0.2, k_folds = 10, \n",
    "                                  seed = 0, generator = None):\n",
    "    \n",
    "    # Split into train/val and test datasets\n",
    "    test_size = int(test_ratio * len(full_dataset))\n",
    "    train_size = len(full_dataset) - test_size\n",
    "    train_set_orig, test_set_orig = random_split(full_dataset, [train_size, test_size], generator = generator)\n",
    "    \n",
    "    # Test dataset loader\n",
    "    test_loader = DataLoader(test_set_orig,\n",
    "                             batch_size = batch_size_test,\n",
    "                             num_workers = 2,\n",
    "                             generator = g_seed)\n",
    "    \n",
    "    # K-fold Cross Validator\n",
    "    train_loader, val_loader = [[]] * k_folds, [[]] * k_folds\n",
    "    kfold = KFold(n_splits = k_folds, shuffle = True, random_state = seed)\n",
    "    for fold, (train_i, val_i) in enumerate(kfold.split(train_set_orig)):\n",
    "        \n",
    "        # Sample train/test dataset from indices\n",
    "        train_sampler = SubsetRandomSampler(train_i, generator = g_seed)\n",
    "        val_sampler = SubsetRandomSampler(val_i, generator = g_seed)\n",
    "        \n",
    "        # Train/Validation dataset loader\n",
    "        train_loader[fold] = DataLoader(train_set_orig,\n",
    "                                        sampler = train_sampler,\n",
    "                                        batch_size = batch_size_train,\n",
    "                                        num_workers = 2,\n",
    "                                        generator = generator)\n",
    "        val_loader[fold] = DataLoader(train_set_orig,\n",
    "                                      sampler = val_sampler,\n",
    "                                      batch_size = batch_size_test,\n",
    "                                      num_workers = 2,\n",
    "                                      generator = generator)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, (len(train_sampler), len(val_sampler), test_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CerealTimeKillersLabels:\n",
    "    \"\"\"Select labels for model prediction.\"\"\"\n",
    "    # Labels used for prediction: Label_info + Label_electrode --> Label_prediction\n",
    "    # CHANGE these with necessity\n",
    "    \n",
    "    # ['subject', 'game', 'gender', 'age', 'disturbance', 'experience', 'memory']\n",
    "    info = []\n",
    "        \n",
    "    # ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "    electrode = ['AF3', 'AF4', 'F3', 'F4', 'F7', 'F8', 'FC5', 'FC6', 'O1', 'O2', 'P7', 'P8', 'T7', 'T8']\n",
    "        \n",
    "    # ['satisfied', 'boring', 'horrible', 'calm', 'funny', 'valence', 'arounsal']\n",
    "    prediction = ['boring', 'horrible', 'calm', 'funny']\n",
    "    # prediction = ['valence', 'arounsal']\n",
    "    \n",
    "    # Fixed variables\n",
    "    fixed = info + prediction\n",
    "    \n",
    "    # Summarise labels for model\n",
    "    label = info + electrode + prediction\n",
    "\n",
    "    \n",
    "class CerealTimeKillersDir:\n",
    "    \"\"\"Directionary for folders.\"\"\"\n",
    "    base = ''\n",
    "    label = f'{base}GameLabels.csv'\n",
    "    game = f'{base}GAMEEMO'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdfddfd13d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whether to allow between-subject dataset mixture?\n",
    "Is_between_subject = False\n",
    "\n",
    "# Model structural settings\n",
    "N_inputtime = 25 # Time window for input sampling (0 for the whole timepoints)\n",
    "N_stridetime = 1 # Temporal leap for input sampling\n",
    "N_perseg = 256 # N per seg of spectrogram\n",
    "N_framerate = 128 # Framerate of spectrogram\n",
    "\n",
    "# Model training settings\n",
    "test_ratio = 0.2 # Proportion of data used for testing\n",
    "batch_size_train = 16 # Number of examples per minibatch during training\n",
    "batch_size_test = 32 # Number of examples per minibatch during validation/testing\n",
    "k_folds = 10 # Number for K-folds\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 2021\n",
    "set_seed(seed = SEED)\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "# Set device\n",
    "# DEVICE = set_device()\n",
    "# print('Current device:', DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chronowanderer/.local/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Implement Dataloader\n",
    "FullDataset = CerealTimeKillersDataLoader(CerealTimeKillersDir, \n",
    "                                          CerealTimeKillersLabels,\n",
    "                                          is_between_subject = Is_between_subject, \n",
    "                                          winlen = N_inputtime, \n",
    "                                          stride = N_stridetime, \n",
    "                                          nperseg = N_perseg, \n",
    "                                          fs = N_framerate)\n",
    "\n",
    "# Implement DataSplitter\n",
    "TrainDataLoader, ValDataLoader, TestDataLoader, DataLength = CerealTimeKillersDataSplitter(FullDataset,\n",
    "                                                                                           batch_size_train = batch_size_train,\n",
    "                                                                                           batch_size_test = batch_size_test,\n",
    "                                                                                           test_ratio = test_ratio,\n",
    "                                                                                           k_folds = k_folds,\n",
    "                                                                                           seed = SEED,\n",
    "                                                                                           generator = g_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test Dataset length: (79, 8, 21)\n",
      "\n",
      "1/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "2/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "3/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "4/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "5/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "6/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "7/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "8/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "9/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n",
      "\n",
      "10/10 Fold\n",
      "----------------------------\n",
      "Input data size: (104, 25, 14, 129)\n",
      "Label example: {'boring': 7.0, 'horrible': 1.0, 'calm': 8.0, 'funny': 3.0}\n"
     ]
    }
   ],
   "source": [
    "print('Train/Val/Test Dataset length:', DataLength)\n",
    "for fold in range(k_folds):\n",
    "    idx = 0\n",
    "    print('\\n%d/%d Fold' % (fold + 1, k_folds))\n",
    "    print('----------------------------')\n",
    "    print('Input data size:', TrainDataLoader[fold].dataset[idx]['spectrogram'].shape)\n",
    "    print('Label example:', TrainDataLoader[fold].dataset[idx]['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
